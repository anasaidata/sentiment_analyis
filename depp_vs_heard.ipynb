{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis | Depp vs Heard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction\n",
    "\n",
    "Twitter extraction by keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter authentificathion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY = \"1528407397403959296-SiXEMki1ykYG1qg3WPht56Dh1nxvfm\"\n",
    "ACCESS_SECRET = \"6BBykwX8DUyDKYpQ46pT7RfPMBM3E7muynpOpYSjgqPwo\"\n",
    "CONSUMER_KEY= 'fVDe8jYU1oWQKkOZlVHd17DDR'\n",
    "CONSUMER_SECRET= '3EPEAxlpGl48QYl2iNBk6HlbrjONLWQ5qoDY61uVReLeHgbX6V'\n",
    "BEARER = \"AAAAAAAAAAAAAAAAAAAAADTKdAEAAAAAEygerXyhYaLCb0wzIuc7wsOak7w%3DJ6QKl3DzawKIUGdQaArG8yovhy8LpUr0MTgovJQ01naJ5b2BRZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tw.Client(bearer_token=BEARER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tweets that contain the hashtag #petday\n",
    "# -is:retweet means I don't want retweets\n",
    "# lang:en is asking for the tweets to be in english\n",
    "query = '#depp -is:retweet lang:en'\n",
    "tweets = client.search_recent_tweets(query=query, tweet_fields=['created_at'], max_results=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-31 16:17:20+00:00</td>\n",
       "      <td>1531671178309513217</td>\n",
       "      <td>Did you not listen to all the audio recordings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-31 16:07:33+00:00</td>\n",
       "      <td>1531668717041483783</td>\n",
       "      <td>How will they decide? #Depp #DeppVHeardTrial #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-31 15:50:45+00:00</td>\n",
       "      <td>1531664486372974593</td>\n",
       "      <td>Remove Amber Heard as ACLU Ambassador of Women...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-31 15:49:35+00:00</td>\n",
       "      <td>1531664196076769281</td>\n",
       "      <td>Jurors to return Tuesday to continue deliberat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-31 15:33:56+00:00</td>\n",
       "      <td>1531660256039813124</td>\n",
       "      <td>@GellertDepp My take on this is that the quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2022-05-31 05:30:22+00:00</td>\n",
       "      <td>1531508364227796992</td>\n",
       "      <td>#JohnnyDeppIsInnocent #Depp the best revenge i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2022-05-31 05:27:26+00:00</td>\n",
       "      <td>1531507623735992320</td>\n",
       "      <td>#AmberHeard was sleeping with James Franco, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2022-05-31 05:23:09+00:00</td>\n",
       "      <td>1531506546831654912</td>\n",
       "      <td>(The Independent):#Johnny #Depp joins Jeff Bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2022-05-31 05:10:56+00:00</td>\n",
       "      <td>1531503474533449728</td>\n",
       "      <td>Rum Diary- I have to admit.. I have never watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2022-05-31 04:51:05+00:00</td>\n",
       "      <td>1531498475694743552</td>\n",
       "      <td>(The Independent):#Johnny #Depp joins Jeff Bec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at                   id  \\\n",
       "0  2022-05-31 16:17:20+00:00  1531671178309513217   \n",
       "1  2022-05-31 16:07:33+00:00  1531668717041483783   \n",
       "2  2022-05-31 15:50:45+00:00  1531664486372974593   \n",
       "3  2022-05-31 15:49:35+00:00  1531664196076769281   \n",
       "4  2022-05-31 15:33:56+00:00  1531660256039813124   \n",
       "..                       ...                  ...   \n",
       "95 2022-05-31 05:30:22+00:00  1531508364227796992   \n",
       "96 2022-05-31 05:27:26+00:00  1531507623735992320   \n",
       "97 2022-05-31 05:23:09+00:00  1531506546831654912   \n",
       "98 2022-05-31 05:10:56+00:00  1531503474533449728   \n",
       "99 2022-05-31 04:51:05+00:00  1531498475694743552   \n",
       "\n",
       "                                                 text  \n",
       "0   Did you not listen to all the audio recordings...  \n",
       "1   How will they decide? #Depp #DeppVHeardTrial #...  \n",
       "2   Remove Amber Heard as ACLU Ambassador of Women...  \n",
       "3   Jurors to return Tuesday to continue deliberat...  \n",
       "4   @GellertDepp My take on this is that the quest...  \n",
       "..                                                ...  \n",
       "95  #JohnnyDeppIsInnocent #Depp the best revenge i...  \n",
       "96  #AmberHeard was sleeping with James Franco, he...  \n",
       "97  (The Independent):#Johnny #Depp joins Jeff Bec...  \n",
       "98  Rum Diary- I have to admit.. I have never watc...  \n",
       "99  (The Independent):#Johnny #Depp joins Jeff Bec...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depp_tweets = pd.DataFrame(tweets.data)\n",
    "depp_tweets.drop_duplicates(inplace=True)\n",
    "depp_tweets.dropna(inplace=True)\n",
    "depp_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tags \"@xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-6878e9be6ead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdepp_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepp_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"@[\\w]*: | *RT*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#np.vectorize(remove_pattern)(depp_tweets['text'], \"@[\\w]*: | *RT*\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdepp_tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-6878e9be6ead>\u001b[0m in \u001b[0;36mremove_pattern\u001b[0;34m(text, pattern_regex)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern_regex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "def remove_pattern(text, pattern_regex):\n",
    "    r = re.findall(pattern_regex, text)\n",
    "    for i in r:\n",
    "        text = re.sub(i, '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "depp_tweets['text'] = np.vectorize(remove_pattern)(depp_tweets['text'], \"@[\\w]*: | *RT*\")\n",
    "depp_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "def fetch_sentiment_using_SIA(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    polarity_scores = sid.polarity_scores(text)\n",
    "    if polarity_scores['neg'] > polarity_scores['pos']:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "def fetch_sentiment_using_textblob(text):\n",
    "    analysis = TextBlob(text)\n",
    "    # set sentiment \n",
    "    if analysis.sentiment.polarity >= 0:\n",
    "        return 'positive'\n",
    "    else: \n",
    "        return 'negative'"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a26509f1ebfbe58e5b9c0be862da0478dce684822429b8f32e207fdb3de41b0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
